{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM 4040 Fall 2020 FINAL PROJECT \n",
    "\n",
    "### Author:\n",
    "\n",
    "Wenjun Yang (wy2347)   \n",
    "\n",
    "Qihang Yang (qy2231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep import *\n",
    "# from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract the midi data from zip file.\n",
    "\n",
    "* the data we use in this project comes from [Classical Piano Midi Page](http://www.piano-midi.de/) \n",
    "* all of them are midi file containing two tracks of piano for left hand and right hand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you don't have to run this block\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile('data/midifile.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare your data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little insight about the input data structure\n",
    "The input data proposed by the original paper is a little bit complex and requires some knowledge about music. \\\n",
    "For more information on background knowledge of music, you can refer to the following two links:\n",
    "* [MIDI_events](https://www.mixagesoftware.com/en/midikit/help/HTML/midi_events.html#:~:text=The%20Note%20Off%20Event%20is,hard%20the%20key%20was%20released.) \n",
    "* [MIDI Turtorial](http://www.music-software-development.com/midi-tutorial.html) \n",
    "\n",
    "We spend quite a lot time trying to figure out the whole logic behind this and provide the following glossary table for your information.\\\n",
    "And for consistency, we will stick to the name convention stated in the original paper.\n",
    "\n",
    "* stateMatrix: matrix of state, for state definition see below\n",
    "* note: 0-77 lower_bound=24; upper_bound=102 \n",
    "* part_position(1) = note\n",
    "* pitchclass = 1 of 12 half steps CDEFGAB b#\n",
    "* part_pitchclass(12): one-hot pitchclass \n",
    "* state: (1,0) (1,1) (0,0) -> denoting holding or repeating a note\n",
    "* context: the count of each pitchclass played in last timestep \n",
    "* part_context(12): rearranged context\n",
    "* part_prev_vicinity(50):\n",
    "\n",
    "#### Note:\n",
    "* input for model: part_position + part_pitchclass + part_prev_vicinity + part_context + beat + [0] \n",
    "* total number of arguments: 1 + 12 + 50 + 12 + 4 + 1 = 80\n",
    "* for each of the 78 note you have 80 arguments in above structure\n",
    "* and we only use sequences of 128 timesteps for training\n",
    "* so the input data form will be 128 X 78 X 80\n",
    "\n",
    "Please refer to prep.py for the details of implementation of data preprocessing part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general data preparation process is as the following flowchart:\n",
    "<img src=\"image/Data Prep.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load liz_et2\n",
      "load scn16_3\n",
      "load haydn_43_1\n",
      "load mendel_op30_3\n",
      "load beethoven_les_adieux_1\n",
      "load br_rhap\n",
      "load grieg_zwerge\n",
      "load haydn_7_1\n",
      "load muss_8\n",
      "load schu_143_2\n",
      "load muss_4\n",
      "load scn68_12\n",
      "load clementi_opus36_1_1\n",
      "load waldstein_3\n",
      "load liz_et_trans5\n",
      "load ty_maerz\n",
      "load ty_juli\n",
      "load rac_op3_2\n",
      "load chpn-p3\n",
      "load gra_esp_4\n",
      "load scn15_5\n",
      "load beethoven_opus10_2\n",
      "load grieg_wedding\n",
      "load mz_330_1\n",
      "load haydn_35_2\n",
      "load chpn_op27_1\n",
      "load schubert_D935_3\n",
      "load mendel_op19_4\n",
      "load schub_d960_1\n",
      "load haydn_9_1\n",
      "load mz_545_1\n",
      "load rac_op33_6\n",
      "load liz_rhap15\n",
      "load alb_esp2\n",
      "load grieg_berceuse\n",
      "load rac_op23_2\n",
      "load bach_850\n",
      "load beethoven_opus22_1\n",
      "load burg_quelle\n",
      "load debussy_cc_4\n",
      "load schubert_D850_4\n",
      "load chpn-p4\n",
      "load mendel_op30_1\n",
      "load pathetique_3\n",
      "load clementi_opus36_6_1\n",
      "load mendel_op62_3\n",
      "load schu_143_1\n",
      "load chpn_op25_e11\n",
      "load scn15_4\n",
      "load schub_d960_4\n",
      "load mz_570_3\n",
      "load clementi_opus36_5_1\n",
      "load scn15_13\n",
      "load grieg_waechter\n",
      "load chpn-p8\n",
      "load brahms_opus1_2\n",
      "load rac_op32_1\n",
      "load liz_et_trans4\n",
      "load haydn_8_1\n",
      "load schuim-1\n",
      "load scn15_11\n",
      "load chpn_op10_e01\n",
      "load scn15_7\n",
      "load burg_agitato\n",
      "load DEB_PASS\n",
      "load chpn_op35_3\n",
      "load beethoven_opus90_2\n",
      "load beethoven_opus10_3\n",
      "load mendel_op53_5\n",
      "load chpn_op25_e2\n",
      "load clementi_opus36_5_3\n",
      "load mz_311_2\n",
      "load schumm-3\n",
      "load debussy_cc_2\n",
      "load scn68_10\n",
      "load haydn_35_1\n",
      "load rac_op32_13\n",
      "load schub_d760_1\n",
      "load deb_prel\n",
      "load beethoven_les_adieux_2\n",
      "load chpn_op35_4\n",
      "load chpn-p20\n",
      "load chpn_op25_e1\n",
      "load debussy_cc_1\n",
      "load rac_op23_7\n",
      "load brahms_opus1_1\n",
      "load clementi_opus36_4_2\n",
      "load bor_ps1\n",
      "load scn15_1\n",
      "load bor_ps5\n",
      "load grieg_halling\n",
      "load god_alb_esp2\n",
      "load liz_et4\n",
      "load schubert_D935_1\n",
      "load pathetique_1\n",
      "load clementi_opus36_2_1\n",
      "load mendel_op19_1\n",
      "load mendel_op30_5\n",
      "load grieg_butterfly\n",
      "load clementi_opus36_4_3\n",
      "load chpn-p9\n",
      "load beethoven_hammerklavier_1\n",
      "load ty_november\n",
      "load schub_d760_4\n",
      "load appass_3\n",
      "load burg_trennung\n",
      "load mz_333_1\n",
      "load chpn-p23\n",
      "load bach_846\n",
      "load hay_40_2\n",
      "load ty_oktober\n",
      "load schumm-5\n",
      "load grieg_kobold\n",
      "load mond_1\n",
      "load ty_september\n",
      "load schubert_D850_1\n",
      "load appass_2\n",
      "load chpn-p15\n",
      "load mz_331_3\n",
      "load schumm-4\n",
      "load alb_esp5\n",
      "load mz_570_2\n",
      "load clementi_opus36_3_2\n",
      "load chpn_op10_e05\n",
      "load chpn_op25_e4\n",
      "load mz_545_3\n",
      "load scn16_7\n",
      "load mz_311_1\n",
      "load waldstein_1\n",
      "load mz_333_3\n",
      "load debussy_cc_6\n",
      "load scn15_3\n",
      "load liz_rhap12\n",
      "load grieg_once_upon_a_time\n",
      "load bach_847\n",
      "load haydn_43_3\n",
      "load clementi_opus36_3_1\n",
      "load beethoven_opus22_4\n",
      "load mond_3\n",
      "load burg_gewitter\n",
      "load burg_spinnerlied\n",
      "load fruehlingsrauschen\n",
      "load chpn_op35_1\n",
      "load scn15_10\n",
      "load haydn_8_3\n",
      "load chpn-p2\n",
      "load rac_op23_5\n",
      "load ty_juni\n",
      "load mz_330_3\n",
      "load bor_ps7\n",
      "load haydn_9_3\n",
      "load chpn_op10_e12\n",
      "load liz_rhap02\n",
      "load scn16_1\n",
      "load chpn-p1\n",
      "load scn16_4\n",
      "load liz_et5\n",
      "load burg_erwachen\n",
      "load liz_rhap09\n",
      "load ty_februar\n",
      "load rav_gib\n",
      "load chpn_op66\n",
      "load scn15_12\n",
      "load rac_op33_8\n",
      "load clementi_opus36_3_3\n",
      "load mz_332_2\n",
      "load haydn_33_1\n",
      "load chpn_op25_e12\n",
      "load bk_xmas2\n",
      "load pathetique_2\n",
      "load chpn-p16\n",
      "load scn15_8\n",
      "load chpn-p14\n"
     ]
    }
   ],
   "source": [
    "training_data = load_data('data/music')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Step 3: Train the theano-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = multi_training.loadPieces(\"music\")\n",
    "\n",
    "m = model.Model([300,300],[100,50], dropout=0.5)\n",
    "\n",
    "multi_training.trainPiece(m, pcs, 10000)\n",
    "\n",
    "pickle.dump( m.learned_config, open( \"output/final_learned_config.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* flowchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(128,78,80))\n",
    "\n",
    "inputs_rotate= tf.keras.backend.permute_dimensions(inputs,(0,2,1,3)) #(batch,78,128,80)\n",
    "\n",
    "time_lstm1 = tf.keras.layers.LSTM(300,return_sequences=True,dropout=0.5)\n",
    "time_lstm2 = tf.keras.layers.LSTM(300,return_sequences=True,dropout=0.5)\n",
    "\n",
    "inter1 = tf.keras.layers.TimeDistributed(time_lstm1)(inputs_rotate) #(batch,78,128,300)\n",
    "inter2 = tf.keras.layers.TimeDistributed(time_lstm2)(inter1) #(batch,78,128,300)\n",
    "\n",
    "note_lstm1 = tf.keras.layers.LSTM(100,return_sequences=True,dropout=0.5)\n",
    "note_lstm2 = tf.keras.layers.LSTM(50,return_sequences=True,dropout=0.5)\n",
    "\n",
    "inter2_rotate= tf.keras.backend.permute_dimensions(inter2,(0,2,1,3)) #(batch,128,78,50)\n",
    "\n",
    "inter3 = tf.keras.layers.TimeDistributed(note_lstm1)(inter2_rotate)\n",
    "inter4 = tf.keras.layers.TimeDistributed(note_lstm2)(inter3)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(2,activation='sigmoid')(inter4) #（batch,128,78,2）\n",
    "\n",
    "model=tf.keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 78, 80)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose_1 (Ten [(None, 78, 128, 80)]     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 78, 128, 300)      457200    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 78, 128, 300)      721200    \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose_2 (Ten [(None, 128, 78, 300)]    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 128, 78, 100)      160400    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 128, 78, 50)       30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128, 78, 2)        102       \n",
      "=================================================================\n",
      "Total params: 1,369,102\n",
      "Trainable params: 1,369,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function\n",
    "# the output of model is the same shape with the sample's state matrix\n",
    "# that is (time,note(78),state(2))\n",
    "# the 2 for each time and note denote the probability of the note being played or articulated repectively in the last step\n",
    "# we use the negative log likelihood to denote the loss, the log function can avoid the numbers being too small\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "#     y_pred=np.asarray(y_pred)\n",
    "#     y_true=np.asarray(y_true)\n",
    "    loss=-tf.keras.backend.mean(tf.math.log(y_pred*y_true+(1-y_pred)*(1-y_true)))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),loss=my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.1716\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.1256\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.1208\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.1210\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.1119\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.1060\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.0957\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.0805\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.0615\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.0525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ca416a7d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen=input_batch_generator(training_data)\n",
    "model.fit_generator(data_gen,epochs=10,steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt=build_single_input(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 78, 80)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(test_dt[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=model.predict(np.asarray(test_dt[0]).reshape(1,128,78,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418.4551392232534"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.square(test_pred.reshape(128,78,2)-np.asarray(test_dt[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=statematrix_to_midi(test_pred.reshape(128,78,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Difference in outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compare between the models (Discussion: The advantage of biaxial LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-axis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inputs = tf.keras.Input(shape=(128,78,80))\n",
    "\n",
    "t_inputs_rotate= tf.keras.backend.permute_dimensions(t_inputs,(0,2,1,3)) #(78,128,80)\n",
    "\n",
    "t_time_lstm1 = tf.keras.layers.LSTM(300,return_sequences=True)\n",
    "t_time_lstm2 = tf.keras.layers.LSTM(300,return_sequences=True)\n",
    "\n",
    "t_inter1 = tf.keras.layers.TimeDistributed(t_time_lstm1)(t_inputs_rotate) #(78,128,80)\n",
    "t_inter2 = tf.keras.layers.TimeDistributed(t_time_lstm2)(t_inter1) #(78,128,80)\n",
    "\n",
    "t_inter2_rotate= tf.keras.backend.permute_dimensions(t_inter2,(0,2,1,3)) #(128,78,80)\n",
    "t_outputs = tf.keras.layers.Dense(2,activation='sigmoid')(t_inter2_rotate) #(128,78,2)\n",
    "\n",
    "time_model=tf.keras.Model(inputs=t_inputs,outputs=t_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 128, 78, 80)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose_5 (Ten [(None, 78, 128, 80)]     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 78, 128, 300)      457200    \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 78, 128, 300)      721200    \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose_6 (Ten [(None, 128, 78, 300)]    0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128, 78, 2)        602       \n",
      "=================================================================\n",
      "Total params: 1,179,002\n",
      "Trainable params: 1,179,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "time_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_model.compile(optimizer=tf.keras.optimizers.Adam(),loss=my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.1755\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.1216\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.1123\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.1003\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.0860\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.0690\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.0459\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.0285\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.0143\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ca4673850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen=input_batch_generator(training_data)\n",
    "time_model.fit_generator(data_gen,epochs=10,steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note_axis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = tf.keras.Input(shape=(128,78,80))\n",
    "\n",
    "n_note_lstm1 = tf.keras.layers.LSTM(100,return_sequences=True)\n",
    "n_note_lstm2 = tf.keras.layers.LSTM(50,return_sequences=True)\n",
    "\n",
    "n_inter3 = tf.keras.layers.TimeDistributed(n_note_lstm1)(n_inputs)\n",
    "n_inter4 = tf.keras.layers.TimeDistributed(n_note_lstm2)(n_inter3)\n",
    "\n",
    "n_outputs = tf.keras.layers.Dense(2,activation='sigmoid')(n_inter4)\n",
    "\n",
    "note_model=tf.keras.Model(inputs=n_inputs,outputs=n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 128, 78, 80)]     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 128, 78, 100)      72400     \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 128, 78, 50)       30200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128, 78, 2)        102       \n",
      "=================================================================\n",
      "Total params: 102,702\n",
      "Trainable params: 102,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "note_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_model.compile(optimizer=tf.keras.optimizers.Adam(),loss=my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 30s 1s/step - loss: 0.2871\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.1456\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.1362\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.1295\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 30s 2s/step - loss: 0.1245\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.1153\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.1068\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 30s 1s/step - loss: 0.0898\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.0743\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ca50d6fd0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen=input_batch_generator(training_data)\n",
    "note_model.fit_generator(data_gen,epochs=10,steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Unsolved problems and Drawbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The model doesn't include factors like velocity and tempo, which makes the generated music somewhat plain and lacking in style.\n",
    "2. The model requires a lot of hand-picked arguments based on empirical knowledge about music.\n",
    "3. The model only deals with single instrument. If we simply run the model on different instruments and then combine each track together, this sure won't give us a good melody. How to make these intruments sound good together could be an interesting task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
